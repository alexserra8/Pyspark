{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21aee26",
   "metadata": {},
   "source": [
    "# 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4573a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark as sp\n",
    "import findspark\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1567006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4da96670",
   "metadata": {},
   "source": [
    "# 1. Find Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94841531",
   "metadata": {},
   "source": [
    "Adding pyspark to sys.path at runtime using the library findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5afbe168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.4.1-bin-hadoop3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65a7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "042661ae",
   "metadata": {},
   "source": [
    "# 2. Creating SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035f20d",
   "metadata": {},
   "source": [
    "One aspect of the explanation why SparkSession is preferable over SparkContext in SparkSession Vs SparkContext battle is that SparkSession unifies all of Spark’s numerous contexts, removing the developer’s need to worry about generating separate contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a69faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000001CC448F69A0>\n"
     ]
    }
   ],
   "source": [
    "#Create the SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "#print the session\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed1d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e489884",
   "metadata": {},
   "source": [
    "# 3. Creating test Pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36205241",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.390212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.825791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.766156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.413412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.390212\n",
       "1  0.516217\n",
       "2  0.825791\n",
       "3  0.766156\n",
       "4  0.413412"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe to try\n",
    "pd_temp = pd.DataFrame(np.random.random(10))\n",
    "pd_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228ae8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(0=0.3902117246181368),\n",
       " Row(0=0.5162169001864194),\n",
       " Row(0=0.8257910132912478),\n",
       " Row(0=0.766156313750286),\n",
       " Row(0=0.4134116640919866)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create spark_temp dataframe from pandas dataframe\n",
    "spark_temp = spark.createDataFrame(pd_temp)\n",
    "spark_temp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe044154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Examine the tables in the catalog\n",
    "print(spark.catalog.listTables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a30b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='temp', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n"
     ]
    }
   ],
   "source": [
    "# Add spark_temp to the catalog\n",
    "spark_temp.createOrReplaceTempView(\"temp\")\n",
    "\n",
    "# Examine the tables in the catalog again\n",
    "print(spark.catalog.listTables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b947a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7cf6027",
   "metadata": {},
   "source": [
    "# 4. Importing Csv to Pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70500adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------------+-----------------+----+---+---+\n",
      "|faa|                name|             lat|              lon| alt| tz|dst|\n",
      "+---+--------------------+----------------+-----------------+----+---+---+\n",
      "|04G|   Lansdowne Airport|      41.1304722|      -80.6195833|1044| -5|  A|\n",
      "|06A|Moton Field Munic...|      32.4605722|      -85.6800278| 264| -5|  A|\n",
      "|06C| Schaumburg Regional|      41.9893408|      -88.1012428| 801| -6|  A|\n",
      "|06N|     Randall Airport|       41.431912|      -74.3915611| 523| -5|  A|\n",
      "|09J|Jekyll Island Air...|      31.0744722|      -81.4277778|  11| -4|  A|\n",
      "|0A9|Elizabethton Muni...|      36.3712222|      -82.1734167|1593| -4|  A|\n",
      "|0G6|Williams County A...|      41.4673056|      -84.5067778| 730| -5|  A|\n",
      "|0G7|Finger Lakes Regi...|      42.8835647|      -76.7812318| 492| -5|  A|\n",
      "|0P2|Shoestring Aviati...|      39.7948244|      -76.6471914|1000| -5|  U|\n",
      "|0S9|Jefferson County ...|      48.0538086|     -122.8106436| 108| -8|  A|\n",
      "|0W3|Harford County Ai...|      39.5668378|      -76.2024028| 409| -5|  A|\n",
      "|10C|  Galt Field Airport|      42.4028889|      -88.3751111| 875| -6|  U|\n",
      "|17G|Port Bucyrus-Craw...|      40.7815556|      -82.9748056|1003| -5|  A|\n",
      "|19A|Jackson County Ai...|      34.1758638|      -83.5615972| 951| -4|  U|\n",
      "|1A3|Martin Campbell F...|      35.0158056|      -84.3468333|1789| -4|  A|\n",
      "|1B9| Mansfield Municipal|      42.0001331|      -71.1967714| 122| -5|  A|\n",
      "|1C9|Frazier Lake Airpark|54.0133333333333|-124.768333333333| 152| -8|  A|\n",
      "|1CS|Clow Internationa...|      41.6959744|      -88.1292306| 670| -6|  U|\n",
      "|1G3|  Kent State Airport|      41.1513889|      -81.4151111|1134| -4|  A|\n",
      "|1OH|     Fortman Airport|      40.5553253|      -84.3866186| 885| -5|  U|\n",
      "+---+--------------------+----------------+-----------------+----+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining path where csv is \n",
    "file_path = \"airports.csv\"\n",
    "\n",
    "# Read in the airports data\n",
    "airports = spark.read.csv(file_path, header=True)\n",
    "\n",
    "# Show the data\n",
    "airports.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8836717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(airports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6208e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='temp', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e17962db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='Aiports_data', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True), Table(name='temp', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n"
     ]
    }
   ],
   "source": [
    "# Add aiports to the catalog\n",
    "airports.createOrReplaceTempView(\"Aiports_data\")\n",
    "\n",
    "# Examine the tables in the catalog again\n",
    "print(spark.catalog.listTables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91f8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
